llm_inference:
  workflow_type: "embed_podcast_text"

  model:
    name: "llama2-uncensored:latest"
    device: "mps"
    temperature: 0.5
    max_tokens: 100

  processing:
    episode_folder: "./audio/podcasts"

  vector_store:
    type: "chromadb"
    vector_store_path: "./chromadb"
    vector_store_collection: "summaries_marketplace_podcasts"
    vector_store_embedding_model: "sentence-transformers/all-mpnet-base-v2"
    vector_store_hnsw_search_algo: "cosine"
    vector_store_query_example: "I don't think inflation will decrease significantly this year"
    chunk_size: 2000
    chunk_overlap: 100
